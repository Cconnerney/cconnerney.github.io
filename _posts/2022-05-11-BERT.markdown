---
layout: post
title: RNN and BERT
description: Sentiment classifier based on Recurrent Neural Network (RNNs) using large-scale pre-trained embeddings. The model is trained and evaluated on tweets.
img: bert.jpg # Add image post (optional)
tags: [NLP, BERT, RNN]
---

<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>sentiment</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>


<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">

<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Sentiment-analysis-with-RNN-and-BERT-embedding">Sentiment analysis with RNN and BERT embedding<a class="anchor-link" href="#Sentiment-analysis-with-RNN-and-BERT-embedding">&#182;</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Bidirectional encoder representation from Transformers (BERT) is a Transformer-based method 
for natural language processing. BERT was primarily trained on language modeling and next 
sentence prediction by masking prediction.</p>
<p>I built a sentiment classifier based on Recurrent Neural Network 
(RNNs) using large-scale pre-trained embeddings. The model is trained and evaluated on 
tweets that have been annotated with three categories (positive, neutral, negative).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">

<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">distutils.errors</span> <span class="kn">import</span> <span class="n">DistutilsExecError</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">index</span>
<span class="kn">import</span> <span class="nn">ssl</span>
<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>

<span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">osp</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">load_pretrained_bert</span><span class="p">,</span> <span class="n">bert_emb_sentence</span><span class="p">,</span> <span class="n">accuracy</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tqdm</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span><span class="p">,</span> <span class="n">nn</span>

<span class="n">idx2label</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;positive&quot;</span><span class="p">,</span> <span class="s2">&quot;neutral&quot;</span><span class="p">,</span> <span class="s2">&quot;negative&quot;</span><span class="p">]</span>
<span class="n">label2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">label</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idx2label</span><span class="p">)}</span>

<span class="n">BERT_EMB_SIZE</span> <span class="o">=</span> <span class="mi">768</span>
<span class="n">OUT_HELDOUT_PATH</span> <span class="o">=</span> <span class="s2">&quot;heldout_pred.txt&quot;</span>
<span class="n">OUT_DEV_PATH</span> <span class="o">=</span> <span class="s2">&quot;dev_pred.txt&quot;</span>
 
<span class="k">class</span> <span class="nc">Classifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rnn_in_dim</span><span class="p">,</span> <span class="n">rnn_hid_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Classifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_in_dim</span> <span class="o">=</span> <span class="n">rnn_in_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_hid_dim</span> <span class="o">=</span> <span class="n">rnn_hid_dim</span>

        <span class="c1"># Layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">rnn_in_dim</span><span class="p">,</span> <span class="n">rnn_hid_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn2logit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">rnn_hid_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_rnn_hid</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initial hidden state.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_hid_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat_seq</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Feeds the words into the neural network and returns the value</span>
<span class="sd">        of the output layer.&quot;&quot;&quot;</span>
        <span class="n">rnn_outs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">feat_seq</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_rnn_hid</span><span class="p">())</span>
                                      <span class="c1"># (seq_len, 1, rnn_hid_dim)</span>
        <span class="n">logit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn2logit</span><span class="p">(</span><span class="n">rnn_outs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># (1 x 3)</span>
        <span class="k">return</span> <span class="n">logit</span>

<span class="k">def</span> <span class="nf">save_bert_embedding</span><span class="p">(</span><span class="n">text_fn</span><span class="p">,</span> <span class="n">out_fn</span><span class="p">):</span>

    <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">text_fn</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)]</span>

    <span class="c1"># save bert embedding to h5 file</span>
    <span class="n">h5_obj</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">out_fn</span><span class="p">,</span><span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">special_dtype</span><span class="p">(</span><span class="n">vlen</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">h5_obj</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;embedding&#39;</span><span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">),),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
    <span class="n">dataset2</span> <span class="o">=</span> <span class="n">h5_obj</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;token_num&#39;</span><span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">),),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">load_pretrained_bert</span><span class="p">()</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pbar</span><span class="p">):</span>
        <span class="n">emb</span><span class="p">,</span> <span class="n">tokens</span> <span class="o">=</span> <span class="n">bert_emb_sentence</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
        <span class="n">save_bert_to_h5</span><span class="p">(</span><span class="n">h5_obj</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">emb</span><span class="p">)</span>

    <span class="n">h5_obj</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">save_bert_to_h5</span><span class="p">(</span><span class="n">h5_obj</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">emb</span><span class="p">):</span>

    <span class="n">dataset2</span> <span class="o">=</span> <span class="n">h5_obj</span><span class="p">[</span><span class="s1">&#39;token_num&#39;</span><span class="p">]</span>
    <span class="n">dataset2</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#len(emb[0])</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">h5_obj</span><span class="p">[</span><span class="s1">&#39;embedding&#39;</span><span class="p">]</span>
    <span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_bert_from_h5</span><span class="p">(</span><span class="n">h5_obj</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">h5_obj</span><span class="p">[</span><span class="s1">&#39;embedding&#39;</span><span class="p">]</span>
    <span class="n">dataset2</span> <span class="o">=</span> <span class="n">h5_obj</span><span class="p">[</span><span class="s1">&#39;token_num&#39;</span><span class="p">]</span>
    <span class="c1"># dataset[idx] embedding</span>
    <span class="c1"># dataset2[idx] token num</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">load_bert</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">emb</span><span class="p">,(</span><span class="n">dataset2</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">BERT_EMB_SIZE</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">load_bert</span>

<span class="k">def</span> <span class="nf">pred_from_logit</span><span class="p">(</span><span class="n">logit</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logit</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;__main__&#39;</span><span class="p">:</span>

    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
    <span class="c1"># args for data</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-train_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;data/train_text.txt&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-train_lab_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;data/train_label.txt&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-dev_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;data/dev_text.txt&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span> <span class="c1">#es</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-dev_lab_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;data/dev_label.txt&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span> <span class="c1">#es</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-test_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;data/heldout_text.txt&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span> <span class="c1">#es</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-train_h5_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;data/bert.h5&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-dev_h5_fn&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;data/bert_dev.h5&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-test_h5_fn&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;data/bert_test.h5&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>

    <span class="c1"># args for classifier training</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-rnn_hid_dim&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="c1">#default = 20</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Dimentionality of RNN hidden state&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-epochs&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of epochs&quot;</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>


    <span class="c1"># extracting bert embeddings, saving as .h5 format </span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">osp</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train_h5_fn</span><span class="p">):</span>
        <span class="n">save_bert_embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">train_h5_fn</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">osp</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dev_h5_fn</span><span class="p">):</span>
        <span class="n">save_bert_embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dev_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dev_h5_fn</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">osp</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">test_h5_fn</span><span class="p">):</span>
        <span class="n">save_bert_embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">test_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">test_h5_fn</span><span class="p">)</span>

    <span class="c1"># pytorch classifier </span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">(</span><span class="n">BERT_EMB_SIZE</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">rnn_hid_dim</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">)</span>
    <span class="n">ce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># training </span>
    <span class="n">labs</span> <span class="o">=</span> <span class="p">[</span><span class="n">label2idx</span><span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train_lab_fn</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)]</span>
    <span class="n">h5_obj</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train_h5_fn</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="c1">#range(args.epochs)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch:&#39;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labs</span><span class="p">)):</span>
            <span class="n">lab</span> <span class="o">=</span> <span class="n">labs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="n">load_bert_from_h5</span><span class="p">(</span><span class="n">h5_obj</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
            <span class="n">logit</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">ce_loss</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">lab</span><span class="p">]))</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">h5_obj</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="c1"># validation </span>
    <span class="n">pred_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">h5_obj</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dev_h5_fn</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">h5_obj</span><span class="p">[</span><span class="s1">&#39;embedding&#39;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">test_num</span><span class="p">):</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">load_bert_from_h5</span><span class="p">(</span><span class="n">h5_obj</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">logit</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred_from_logit</span><span class="p">(</span><span class="n">logit</span><span class="p">)</span>
        <span class="n">pred_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx2label</span><span class="p">[</span><span class="n">pred</span><span class="p">])</span>
    <span class="n">h5_obj</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">OUT_DEV_PATH</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">pred_list</span><span class="p">:</span> <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">pred</span><span class="o">+</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">out</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy</span><span class="p">(</span><span class="s2">&quot;dev_pred.txt&quot;</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">dev_lab_fn</span><span class="p">)))</span>

    <span class="c1"># testing</span>
    <span class="n">pred_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">h5_obj</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">test_h5_fn</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">h5_obj</span><span class="p">[</span><span class="s1">&#39;embedding&#39;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">test_num</span><span class="p">):</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">load_bert_from_h5</span><span class="p">(</span><span class="n">h5_obj</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="n">logit</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred_from_logit</span><span class="p">(</span><span class="n">logit</span><span class="p">)</span>
        <span class="n">pred_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx2label</span><span class="p">[</span><span class="n">pred</span><span class="p">])</span>
    <span class="n">h5_obj</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">out</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">OUT_HELDOUT_PATH</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">pred_list</span><span class="p">:</span> <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">pred</span><span class="o">+</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">out</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Utils">Utils<a class="anchor-link" href="#Utils">&#182;</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">

<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">set_dir</span><span class="p">(</span><span class="s1">&#39;./cache/&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_pretrained_bert</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;huggingface/pytorch-transformers&#39;</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="s1">&#39;bert-base-cased&#39;</span><span class="p">)</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;huggingface/pytorch-transformers&#39;</span><span class="p">,</span> <span class="s1">&#39;tokenizer&#39;</span><span class="p">,</span> <span class="s1">&#39;bert-base-cased&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span>
    
<span class="k">def</span> <span class="nf">bert_emb_sentence</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="c1"># tokenization</span>
    <span class="n">indexed_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">indexed_tokens</span><span class="p">)</span>

    <span class="c1"># bert embedding extraction</span>
    <span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">indexed_tokens</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">emb</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">emb</span><span class="p">,</span> <span class="n">tokens</span>

<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">pred_fn</span><span class="p">,</span> <span class="n">ref_fn</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">pred_fn</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)]</span>
    <span class="n">labs</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">ref_fn</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)]</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">labs</span><span class="p">)</span>

    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">lab</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">pred</span><span class="o">==</span><span class="n">lab</span><span class="p">:</span> <span class="n">total</span><span class="o">+=</span><span class="mi">1</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">total</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">labs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">acc</span>

<span class="c1"># testing</span>
<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1">#model, tokenizer = load_pretrained_bert()</span>
    <span class="c1">#emb, tokens = bert_emb_sentence(&#39;this movie is awesome!&#39;, model, tokenizer)</span>
    <span class="c1">#print(emb.size(), tokens)</span>
    <span class="c1">#acc = accuracy(&#39;heldout_pred_rnn.txt&#39;, &#39;data/heldout_label.txt&#39;)</span>
    <span class="c1">#print(&#39;acc:&#39;, acc)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
</body>


</html>
